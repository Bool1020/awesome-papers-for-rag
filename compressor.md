# Awesome resources about evidence selection component in the RAG system

üî• **Must-read papers for evidence distillation component in RAG.**

üèÉ **Coming soon: Add one-sentence intro to each paper.**

üåü **We greatly appreciate any contributions via PRs, issues, emails, or other methods.**


## Introduction

The retrieved documents often contain a list of passages which are ranked by their relevance score to the question. It would be costly to directly input these passages into the LLM. One one hand, the relevance score of these passages does not necessarily indicate their usefulness for answer generation, which could introduce noise to the LLM. On the other hand, the length of the list could exceed the length limit of the LLM. Thus, the evidence distillation (also called compressor) component is introduced to select and compress the retrieved content.



## Table of Content (ToC)


- [Selective Methods](#selection)
- [Abstractive Methods](#abstractive)


## 1. Selective Methods <a id="methods"></a>

| Date       | Title                                                        | Authors                                                      | Orgnization                   | Abs                                                          |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------- | ------------------------------------------------------------ |
| 2023/10/23 | [PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter](https://aclanthology.org/2023.emnlp-main.326.pdf) <br> | Haoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang, Ning Cheng, Ming Li,  Jing Xiao | Ping An Technology (Shenzhen) | <small>**PRCA** propose a trainable PluggableReward-Driven Contextual Adapter. It proposed a two-stage context adapter training scheme.<br />¬†Context extraction stage: Use the BERT model to extract context based on supervised data, minimizing the difference between the ground truth generated by the model without GPT4 in extracting context.<br />Reward driven stage: Use the rouge-l score between the answer generated by the black box model and the standard answer as a reward, and use PPO method for reinforcement learning.</small> |
| 2023/11/14 | [Learning to Filter Context for Retrieval-Augmented Generation](https://arxiv.org/pdf/2311.08377.pdf)<br>[[code](https://github.com/zorazrw/filco)] | Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, Graham Neubig | Carnegie Mellon University    | <small>**FILCO** Identifying useful context through lexical and information theory based methods<br/>It also train a context filtering model that can filter the retrieved context during testing, thereby improving the quality of the context provided to the generator</small> |

## 2. Abstractive Methods <a id="abstractive"></a>

| Date       | Title                                                                                                           | Authors                                  | Orgnization                                                                                                   | Abs                                                                                             |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/04/12| [RECOMP: Improving Retrieval-Augmented LMs With Compression and Selective Augmentation](https://arxiv.org/pdf/2310.04408.pdf) <br>[[code](https://github.com/carriex/recomp): ![](https://img.shields.io/github/stars/carriex/recomp.svg?style=social)|Fangyuan Xu, Weijia Shi, Eunsol Choi1 |The University of Texas at Austin, University of Washington|<small>**Recomp** introduces two types of compressors: an <u>extractive</u> compressor that selects pertinent sentences from retrieved documents, and an <u>abstractive</u> compressor that produces concise summaries by amalgamating information from multiple documents.</small>|
|2023/11/15| [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](https://arxiv.org/pdf/2311.09210.pdf) |Wenhao Yu, Hongming Zhang, Xiaoman Pan, Kaixin Ma, Hongwei Wang, Dong Yu |Tecent AI Lab, Seattle|<small>**Chain-of-Note:¬†**Chain of note (CON) was proposed to improve the robustness of RALM in the face of noise, irrelevant documents, and unknown scenarios.<br/>The core idea is to generate continuous reading notes for the retrieved documents, so as to thoroughly evaluate their relevance without any given questions, and integrate this information together to form the final answer.</small>|

