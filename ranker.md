# Awesome resources about retrieval component in the RAG system

ðŸ”¥ **Must-read papers for retrieval component in RAG.**

ðŸŒŸ **We greatly appreciate any contributions via PRs, issues, emails, or other methods.**


## Introduction

Coming soon ...


## Table of Content (ToC)


- [Retrieval Methods](#retrieval)
  - [Two-tower Retriever (Tuning Embeddings)](#tunembedding)
  - [LLM-based Retriever](#aligning)
  - [LLM-guided Retriever](#llm-guided-retriever)
  - [Structured Retriever](#structured-retriever)

- [ReRanking Methods](#rerank)

- [Analysis about Retrieval](#analysis)





## 1. Retrieval Methods <a id="retrieval"></a>

### 1.1 Two-tower Retriever (Tuning Embeddings) <a id="tunembedding"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Base | Dataset     |
|------------|-------------------|---------------|------------------------|-----------------|------------------|--------------|
|2024/12/17| [LLMs are Also Effective Embedding Models: An In-depth Overview](https://arxiv.org/pdf/2412.12591) | Chongyang Tao, Tao Shen, Shen Gao, et. al.| Beihang University, Tencent|<details><summary><small>Survey Paper</small></summary><small>...</small></details>| -| <sub>-</sub>|
|2024/8/29| [Conan-embedding: General Text Embedding with More and Better Negative Samples](https://arxiv.org/pdf/2408.15710) | Shiyu Li, Yang Tang, Shi-Zhen Chen, et. al.| Peking University, Tencent|<details><summary><small>This paper presents **conan-embedding** ...</small></summary><small>This work present **Conan-embedding**, which maximizes the utilization of more and higher-quality negative examples.</small></details>| <sub>MTEB</sub>|
|2024/3/29| [Gecko: Versatile Text Embeddings Distilled from Large Language Models](https://arxiv.org/pdf/2403.20327) | Jinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, et. al.| Google Deepmind|<details><summary><small>This paper presents **Gecko** ...</small></summary><small>This work present **Gecko**, a compact and versatile text embedding modle, which employs a two-stage distillation process by generating data and refining data quality based on large language models</small></details>| <sub>MTEB</sub>|
|2024/2/23| [Repetition Improves Language Model Embeddings](https://arxiv.org/pdf/2402.15449.pdf) <br>[[code](https://github.com/jakespringer/echo-embeddings): ![](https://img.shields.io/github/stars/jakespringer/echo-embeddings.svg?style=social)] |Jacob Mitchell Springer, Suhas Kotha, Daniel Fried, et. al.| CMU| <details><summary><small>This paper presents **echo embeddings** ...</small></summary><small>This work present "**echo embeddings**", in which they repeat the input twice in context and extract embeddings from the second occurrence (i.e., repetition captures bidirectional information)</small></details>| <sub>MTEB</sub>|
|2024/2/15| [Generative Representational Instruction Tuning](https://arxiv.org/abs/2402.09906.pdf), <br>[[code](https://github.com/ContextualAI/gritlm): ![](https://img.shields.io/github/stars/ContextualAI/gritlm.svg?style=social)]|Niklas Muennighoff, Hongjin Su, Liang Wang, et. al. | Contextual AI, The University of Hong Kong, Microsoft|<details><summary><small>This paper presents **GRIT** ...</small></summary><small>This work introduces generative representational instruction tuning (**GRIT**) whereby a large language model is trained to handle both generative and embedding tasks by distinguishing between them through instructions</small></details>| <sub>MTEB</sub>|
|2024/2/10 | [BGE M3-Embedding: Multi-Lingual, Multi-Functionality,Multi-Granularity Text Embeddings Through Self-Knowledge Distillation](https://arxiv.org/abs/2402.03216.pdf)|Liang Wang, Nan Yang, Xiaolong Huang, et. al.|BAAI, USTC|<details><summary><small>This paper presents **M3-embedding** ...</small></summary><small>This work present a new embedding model, called **M3-Embedding**, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity</small></details>| <sub>MIRACL, MKQA, MLDR</sub>|
|2024/1/19| [Improving Text Embeddings with Large Language Models](https://arxiv.org/abs/2401.00368.pdf)| Jianlv Chen, Shitao Xiao, Peitian Zhang, et. al.|Microsoft|<details><summary><small>This paper presents ...</small></summary><small>This work introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps.</small></details>| <sub> BEIR, MTEB</sub>|
|2023/10/25|[Retrieve Anything To Augment Large Language Models](https://arxiv.org/abs/2310.07554)<br>[[code](https://github.com/FlagOpen/FlagEmbedding): ![](https://img.shields.io/github/stars/FlagOpen/FlagEmbedding.svg?style=social)]|AutPeitian Zhang, Shitao Xiao, Zheng Liu, et. al.|BAAI, Renmin Univeristy of China, University of Montreal|<details><summary><small>This paper presents **LLM-Embedder** ...</small></summary><small>This work present a novel approach, the **LLM-Embedder**, which comprehensively supports the diverse retrieval augmentation needs of LLMs with one unified embedding model.</small></details>| <sub>MMLU, PopQA</sub>|
|2023/5/30| [One Embedder, Any Task: Instruction-Finetuned Text Embeddings](https://arxiv.org/abs/2212.09741)<br>[[code](https://github.com/xlang-ai/instructor-embedding): ![](https://img.shields.io/github/stars/xlang-ai/instructor-embedding.svg?style=social)]|Hongjin Su, Weijia Shi, Jungo Kasai, et. al.|University of Hong Kong, University of Washingtong, Meta AI, Allen Institute for AI|<details><summary><small>This paper presents **INSTRUCTOR** ...</small></summary><small>This work introduce **INSTRUCTOR**, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions).</small></details>|GTR| <sub>MTEB</sub>|
|2022/9/23| [Promptagator: Few-shot Dense Retrieval From 8 Examples](https://arxiv.org/abs/2209.11755)|Zhuyun Dai, Vincent Y. Zhao, Ji Ma, et. al.|Google Research|<details><summary><small>This paper presents **Promptagator** ...</small></summary><small>This work propose Prompt-base Query Generation for Retriever (**Promptagator**), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data.</small></details>|FLAN| <sub>BEIR</sub>|


### 1.2 LLM-based Retriever<a id="aligning"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/12/24|[Making Large Language Models A Better Foundation For Dense Retrieval](https://arxiv.org/pdf/2312.15503.pdf) <br>[[code](https://github.com/FlagOpen/FlagEmbedding): ![](https://img.shields.io/github/stars/FlagOpen/FlagEmbedding.svg?style=social)]| Chaofan Li, Zheng Liu, Shitao Xiao, et. al.|BAAI, BUPT|<details><summary><small>This paper presents LLaRA ...</small></summary><small>This work includes **LLaRA** (LLM Adapted for dense RetriAl), which introduce two pretext training tasks EBAE (Embedding-Based Auto-Encoding) and EBAR (Embedding-Based Auto-Regression) to improve LLaMA for dense retrieval.</small></details>|<sub>MS MARCO passage&document, BEIR</sub>|


<!--
|2023/12/16| [UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation](https://arxiv.org/abs/2303.08518.pdf)<br>[[code](https://github.com/microsoft/LMOps): ![](https://img.shields.io/github/stars/microsoft/LMOps.svg?style=social) |Daixuan Cheng, Shaohan Huang, Junyu Bi, et. al.|Microsoft|<details><summary><small>This paper presents UPRISE ...</small></summary><small>This work propose  UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input.</small></details>|
-->

### 1.3 LLM-guided Retriever<a id="llm-guided-retriever"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/03/27| [LLatrieval: LLM-Verified Retrieval for Verifiable Generation](https://arxiv.org/pdf/2311.07838.pdf)<br>[[code](https://github.com/BeastyZ/LLM-Verified-Retrieval): ![](https://img.shields.io/github/stars/BeastyZ/LLM-Verified-Retrieval.svg?style=social))]| Xiaonan Li, Changtai Zhu, Linyang Li, et. al.| Fudan University | <details><summary><small>This paper presents LLatrieval ...</small></summary><small>This work proposes **LLatrieval** (LLM-verified Retrieval), where the LLM iteratively provides feedback to the retrieval through verify-update iterations. 1) **Retrieval Verification** is implemented by prompting LLM to give binary label, and 2) **Retrieval Update** takes LLM to progressively scan the document candidates returned by the retriever and selects the supporting documents.</small></details>|<sub>ALCE</sub>|
|2024/3/15 | [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](https://arxiv.org/abs/2403.10081) <br>[[code](https://github.com/oneal2000/DRAGIN): ![](https://img.shields.io/github/stars/oneal2000/DRAGIN.svg?style=social)] | Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu|  Tsinghua University, Beijing Institute of Technology| <details><summary><small>This paper presents DRAGIN ...</small></summary><small>This work introduce a new framework, **DRAGIN**, i.e., Dynamic Retrieval Augmented Generation based on the real-time Information Needs of LLMs. This framework is specifically designed to make decisions on when and what to retrieve based on the LLMâ€™s real-time information needs during the text generation process.</small></details>|<sub>2WikiMHQA, HotpotQA, IIRC, StrategyQA</sub>|
|2023/5/26| [Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In](https://arxiv.org/abs/2305.17331.pdf) <br> [[code](https://github.com/OpenMatch/Augmentation-Adapted-Retriever): ![](https://img.shields.io/github/stars/OpenMatch/Augmentation-Adapted-Retriever.svg?style=social)] |Zichun Yu, Chenyan Xiong, Shi Yu, Zhiyuan Liu|Tsinghua University, Microsoft|<details><summary><small>This paper presents AAR ...</small></summary><small>This work introduce augmentation-adapted retriever (AAR), which takes a black-box LLM to score positive documents (so called LLM-preferred signals) for fine-tuning a pre-trained retriever.</small></details>|<sub>MMLU, PopQA</sub>|


### 1.4 Structured Retriever <a id="structured-retriever"></a>
| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/01/31|[RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval](https://arxiv.org/abs/2401.18059) [[code](https://github.com/parthsarthi03/raptor): ![](https://img.shields.io/github/stars/parthsarthi03/raptor.svg?style=social)]|Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, Christopher D. Manning|Stanford|<details><summary><small>This paper presents RAPTOR ...</small></summary><small>We introduce the novel approach of recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across lengthy documents at different levels of abstraction.  On question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example, by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by 20% in absolute accuracy.</small></details>|<sub>NarrativeQA, QASPER, QuALITY</sub>|


## 2. ReRanking Methods <a id="rerank"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2025/02/25|[Rank1: Test-Time Compute for Reranking in Information Retrieval](https://arxiv.org/pdf/2502.18418) [[code](https://github.com/orionw/rank1): ![](https://img.shields.io/github/stars/orionw/rank1.svg?style=social)]|Orion Weller, Kathryn Ricci Eugene Yang, Andrew Yates, et al.|Johns Hopkins University|<details><summary><small>This paper presents **Rank1** ...</small></summary><small> This work sample 635,000  examples of R1's thought process on the MS MARCO dataset. It then finetunes the qwen 2.5 model on these reasoning chains and find they show remarkable reasoning capabilities.</small></details>|<sub>BRIGHT</sub>|
|2025/02/06|[TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy](https://arxiv.org/pdf/2406.11678) [[code](https://github.com/chenyiqun/TourRank): ![](https://img.shields.io/github/stars/chenyiqun/TourRank.svg?style=social)]|Yiqun Chen, Qi Liu, Yi Zhang, et al. | Renmin University & Baidu|<details><summary><small>This paper presents **TourRank** ...</small></summary><small> This paper propose a zero-shot document ranking method called **TourRank**. It first groups candidate documents and prompt LLM to select the most relevant one in each group. It also designes a points systems to assign different points to each document based on its ranking in each round tournament.</small></details>|<sub>BEIR, TREC-DL</sub>|
|2024/05/30|[A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models](https://arxiv.org/pdf/2310.09497) [[code](https://github.com/ielab/llm-rankers): ![](https://img.shields.io/github/stars/ielab/llm-rankers.svg?style=social)]|Shengyao Zhuang, Honglei Zhuang, Bevan Koopman, Guido Zuccon | CSIRO, Australia|<details><summary><small>This paper presents **Setwise Prompting** ...</small></summary><small> This work focus on LLM-based zero-shot document ranking, and introduce an **Setwise** prompting strategy. It instructs LLMs to select the most relevant document to the query from a set of candidate documents.</small></details>|<sub>BEIR, TREC-DL</sub>|
|2024/05/23|[Top-Down Partitioning for Efficient List-Wise Ranking](https://arxiv.org/pdf/2405.14589v1) [[code](https://github.com/Parry-Parry/TDPart): ![](https://img.shields.io/github/stars/Parry-Parry/TDPart.svg?style=social)]|Andrew Parry, Sean MacAvaney, Debasis Ganguly|University of Glasgow|<details><summary><small>This paper presents **TDPart** ...</small></summary><small> This work partitions a ranking to depth k and processes documents to-down. At each round, it selects a pivot document, and compared it with documents from each group. Those winner documents of each group are collected as the input of next round.</small></details>|<sub>MSMARCO, TREC-DL, BEIR</sub>|
|2023/04/19|[Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents](https://arxiv.org/abs/2304.09542) [[code](https://github.com/sunnweiwei/RankGPT): ![](https://img.shields.io/github/stars/sunnweiwei/RankGPT.svg?style=social)]|Weiwei Sun, Lingyong Yan, Xinyu Ma, et al., | Shandong University|<details><summary><small>This paper presents **RankGPT** ...</small></summary><small> This work first investigates prompting ChatGPT on passage re-ranking tasks, and find LLMs show limited performance. It proposes an instructional permutation generation method, and use sliding window to address context length limitation of LLMs.</small></details>|<sub>BEIR, TREC-DL</sub>|


## 3. Analysis about Retrieval<a id="analysis"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/7/14 | [The Power of Noise: Redefining Retrieval for RAG Systems](https://arxiv.org/abs/2401.14887) <br>[[code](https://github.com/florin-git/The-Power-of-Noise): ![](https://img.shields.io/github/stars/florin-git/The-Power-of-Noise.svg?style=social)] | F. Cuconasu, G. Trappolini, F. Siciliano, etl. al.|  Sapienza University of Rome| <details><summary><small>This paper studies noise passages ...</small></summary><small>This paper studied the impact of noise passages in RAG, and found that adding random documents in the prompt improves the LLM accuracy by up to 35% on the NQ dataset.</small></details>|<sub>NQ-open (subset of NQ)</sub>|

