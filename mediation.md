# Awesome resources about <font color='blue'>Mediation</font> component in the RAG system

🔥 **Must-read papers for *mediation* component in RAG.**

<!--- 🏃 **Coming soon: Add one-sentence intro to each paper.**  --->

🌟 **We greatly appreciate any contributions via PRs, issues, emails, or other methods.**


## Introduction

The retrieved documents often contain a list of passages which are ranked by their relevance score to the question. It would be costly to directly input these passages into the LLM. On one hand, <u>the relevance score of these passages does not necessarily indicate their usefulness for answer generation, which could introduce noise to the LLM</u>. On the other hand, <u>the length of the list could exceed the length limit of the LLM</u>. Thus, the mediation (also called post-retrieval) component is introduced to select or compress the retrieved content.



## Table of Content (ToC)
- [Re-ranking based Methods](#rerank)
  - [Adapting LLM as Reranker](#llm-based-ranker): re-ranking documents/passages to obtain a new ranked list. 
- [Compression-based Adapter](#compress)
  - [Selective Methods](#selection): Selective Methods aims to select a subset of tokens from original contexts. 
  - [Abstractive Methods](#abstractive): Abstractive Methods usually compress contexts by generating summarys.
- [Thoughts-based Methods](#thoughts)
- [Preference Alignment Methods](#align)


## 1. Re-ranking based Methods <a id="rerank"></a>

### 1.1 Adapting LLM as Reranker <a id="llm-based-ranker"></a>
| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/03/28 | [Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting](https://arxiv.org/pdf/2306.17563.pdf) | Zhen Qin, Rolf Jagerman, Kai Hui, et al.|Google Research|<details><summary><small>This paper presents PRP ...</small></summary><small>This work introduces Pairwise Ranking Prompting (PRP) for ranking with LLMs. Three variant of PRP: 1) all pair comparisons $O(N^2)$, 2) Sorting-based, i.e., Heapsort, $O(N\times \log(N))$, 3) Sliding window, i.e., Bubble Sort for Top-K, $O(N)$.</small></details>| <sub>TREC-DL2019&2020</sub>|
|2024/02/20 | [Bridging the Preference Gap between Retrievers and LLMs](https://arxiv.org/pdf/2401.06954) | Zixuan Ke, Weize Kong, Cheng Li, et al.|Google Research|<details><summary><small>This paper presents BGM ...</small></summary><small>This work trains a seq2seq bridge model (directly generates passage IDs) to jointly accomplish reranking and selection, adapting the retrieved information to be LLM-friendly. It employs a SL and RL training scheme to optimize the adapation process.</small></details>| <sub>NQ, HotpotQA, Avocado Email, Amazon Book</sub>|
|2023/12/5 | [Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models](https://arxiv.org/pdf/2312.02969.pdf) | Xinyu Zhang, Sebastian Hofstätter, Patrick Lewis, et al.|University of Waterloo, Cohere, Comcast Applied AI|<details><summary><small>This paper presents RepLLaMA ...</small></summary><small>This work finetunes LLaMA model both as a dense retriever (RepLLaMA) and as a point-wise reranker (RankLLaMA) for both passage retrieval and document retrieval using the MS MARCO datasets.</small></details>| <sub>TREC-DL 19 & 20</sub>|
|2023/10/27 | [Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents](https://arxiv.org/pdf/2304.09542.pdf)<br>[[code](https://github.com/sunnweiwei/RankGPT): ![](https://img.shields.io/github/stars/sunnweiwei/RankGPT.svg?style=social))] | Weiwei Sun, Lingyong Yan, Xinyu Ma, et al.|Shandong University, Baidu Inc. |<details><summary><small>This paper presents ...</small></summary><small>This work introduces *intructional permutation generation with a sliding window strategy* to investigate the ability of black-box LLMs (ChatGPT and GPT-4) in reranking. It also distill the ranking result of ChatGPT into a small ranker using permutation distillation.</small></details>| <sub>TREC-DL 19&20, BEIR, Mr.TyDi</sub>|
|2023/10/21 | [Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels](https://arxiv.org/pdf/2310.14122.pdf) | Honglei Zhuang, Zhen Qin, Kai Hui, Junru Wu, et al. |Google Research |<details><summary><small>This paper presents ...</small></summary><small>This work proposes to incorporate fine-grained relevance labels into the prompt for point-wise LLM rankers .</small></details>| <sub>BEIR</sub>|
|2023/10/20 | [Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking](https://arxiv.org/pdf/2310.13243.pdf) | Shengyao Zhuang, Bing Liu, Bevan Koopman, Guido Zuccon |CSIRO |<details><summary><small>This paper presents ...</small></summary><small>This work finds that open-source LLMs can be effective point-wise rankers by asking them to generate the query given the content of a document.</small></details>| <sub>BEIR</sub>|
|2023/10/12 | [Fine-Tuning LLaMA for Multi-Stage Text Retrieval](https://arxiv.org/pdf/2310.08319.pdf)| Xueguang Ma, Liang Wang, Nan Yang et al.|David R. Cheriton School of Computer Science, University of Waterloo, Microsoft Research|<details><summary><small>This paper presents ...</small></summary><small>This work studies how to construct GPT-free listwise rerankers based on open-source LLM models</small></details>| <sub>MS Marco passage, TREC-DL 19&20</sub>|
|2023/5/1| [Say Goodbye to Irrelevant Search Results: Cohere Rerank Is Here](https://txt.cohere.com/rerank)| NILS REIMERS, SYLVIE SHI, LUCAS FAYOUX, ELLIOTT CHOI| Cohere| <details><summary><small>This work presents Cohere Rerank ...</small></summary><small>This work proposes Cohere Rerank,which can provide a powerful semantic boost to the search quality of any keyword or vector search system without requiring any overhaul or replacement.</small></details>| <sub>MIRACL, TREC-DL 19&20, NQ</sub>|


## 2. Compression-based Adapter <a id="compress"></a>
### 2.1 Selective Methods <a id="selection"></a>
| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/03/21| [FIT-RAG: Black-Box RAG with Factual Information and Token Reduction](https://arxiv.org/pdf/2403.14374) |Yuren Mao, Xuemei Dong, Wenyi Xu, et al. |Zhejiang University |<details><summary><small>This paper presents FIT-RAG ...</small></summary><small>**FIT-RAG** utilizes the factual information in the retrieval and reduces the number of tokens for augmentation. It consists of five components: a similarity-based retriever, a bi-label document scorer, a bi-faceted self-knowledge recognizer, a sub-document-level token reducer and a prompt construction module.</small></details>| <sub>TriviaQA, NQ, PopQA</sub> |
|2024/03/19| [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/abs/2403.12968) |Zhuoshi Pan, Qianhui Wu, et al. |Microsoft Corporation |<details><summary><small>This paper presents LLMLingua-2...</small></summary><small>**LLMLingua-2** formulate prompt compression as a token classification problem to guarantee the faithfulness of the compressed prompt to the original one, and use a Transformer encoder as the base architecture to capture all essential information for prompt compression from the full bidirectional context.  </small></details>| <sub>MeetingBank, LongBench, ZeroScrolls, GSM8K, BBH</sub> |
|2023/11/14| [Learning to Filter Context for Retrieval-Augmented Generation](https://arxiv.org/pdf/2311.08377) |Zhiruo Wang, Jun Araki, et al. |Carnegie Mellon University |<details><summary><small>This paper presents FILCO...</small></summary><small>**FILCO** improves the quality of the context provided to the generator by (1) identifying useful context based on lexical and information-theoretic approaches, and (2) training context filtering models that can filter retrieved contexts at test time.</small></details>| <sub>NQ, TriviaQA, ELI5, FEVER, WoW</sub> |
|2023/10/10| [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://arxiv.org/abs/2310.06839) |Huiqiang Jiang, Qianhui Wu, et al. |Microsoft Corporation |<details><summary><small>This paper presents LongLLMLingua ...</small></summary><small>**LongLLMLingua** conducts prompt compression towards improving LLMs’ perception of the key information to address three challenges: higher computational/financial cost, longer latency, and inferior performance. </small></details>| <sub> LongBench, ZeroSCROLLS, MuSiQue, LooGLE</sub> |
|2023/10/09| [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://arxiv.org/abs/2310.05736) |Huiqiang Jiang, Qianhui Wu, et al. |Microsoft Corporation |<details><summary><small>This paper presents LLMLingua...</small></summary><small>**LLMLingua** is a coarse-to-fine prompt compression method that involves a budget controller to maintain semantic integrity under high compression ratios, a token-level iterative compression algorithm to better model the interdependence between compressed contents, and an instruction tuning based method for distribution alignment between language models.  </small></details>|  <sub>GSM8K, BBH, ShareGPT, and Arxiv-March23</sub> |
|2023/09/02| [LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs](https://arxiv.org/abs/2309.00841) |Md Adnan Arefeen, Biplob Debnath, Srimat Chakradhar |NEC Laboratories America |<details><summary><small>This paper presents LeanContext ...</small></summary><small>**LeanContext** extracts k key sentences from the context that are closely aligned with the query. LeanContext introduces a reinforcement learning technique that dynamically determines k based on the query and context. The rest of the less important sentences are reduced using a free open source text reduction method. </small></details>| <sub>Arxiv, BBC News</sub> |



### 2.2 Abstractive Methods <a id="abstractive"></a>


| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/07/04| [Attribute First, then Generate: Locally-attributable Grounded Text Generation](https://arxiv.org/abs/2403.17104) <br>[[code](https://github.com/lovodkin93/attribute-first-then-generate): ![](https://img.shields.io/github/stars/lovodkin93/attribute-first-then-generate.svg?style=social)]|Aviv Slobodkin, Eran Hirsch et al. |Bar-Ilan University|<details><summary><small>This paper presents AttrFirst...</small></summary><small>**AttrFirst** propose a locally-attributable text generation approach, with prompt-based three steps: 1) content selection (choosing relevant spans from source texts), 2)sentence-level planning (organizing and grouping content), 3)sentence-by-sentence generation (based on selected and structured output).</small></details>| <sub>DUC, TAC, MultiNews </sub> |
|2023/10/25| [TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction](https://arxiv.org/abs/2310.15556) |Junyi Liu, Liangzhi Li, et al. |Meetyou AI Lab|<details><summary><small>This paper presents TCRA...</small></summary><small>**TCRA** propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic.</small></details>| <sub>FRDB</sub> |
|2023/04/12| [RECOMP: Improving Retrieval-Augmented LMs With Compression and Selective Augmentation](https://arxiv.org/pdf/2310.04408.pdf) <br>[[code](https://github.com/carriex/recomp): ![](https://img.shields.io/github/stars/carriex/recomp.svg?style=social)]|Fangyuan Xu, Weijia Shi, Eunsol Choi1 |The University of Texas at Austin, University of Washington|<details><summary><small>This paper presents Recomp...</small></summary><small>**Recomp** introduces two types of compressors: an <u>extractive</u> compressor that selects pertinent sentences from retrieved documents, and an <u>abstractive</u> compressor that produces concise summaries by amalgamating information from multiple documents.</small></details>| <sub>WikiText-103, NQ, TriviaQA, HotpotQA</sub> |

## 3. Thoughts-based Methods <a id="thoughts"></a>
| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/03/28 | [ACTIVERAG: Autonomously Knowledge Assimilation and Accommodation through Retrieval-Augmented Agents](https://arxiv.org/pdf/2402.13547) [[code](https://github.com/OpenMatch/ActiveRAG): ![](https://img.shields.io/github/stars/OpenMatch/ActiveRAG.svg?style=social)]| Zhipeng Xu, Zhenghao Liu, Yukun Yan, et al.|Northeastern University, China|<details><summary><small>This paper presents *ActiveRAG* ...</small></summary><small>The ActiveRAG workflow follows three-step: 1) the *Self-Inquiry Agent* produce chain-of-thought (P) to answer the question using LLM based on Q. 2) The *Knowledge Assimilation agent* generates an assimilation rational (T) based on Q and D. 3) The *Thought Accommodation agent* generates responses based on (Q, T,P).</small></details>| <sub>PopQA, TriviaQA, NQ, 2WikiMHQA, ASQA</sub> |
|2023/10/23 | [Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy](https://arxiv.org/pdf/2305.15294.pdf) | Zhihong Shao, Yeyun Gong, yelong shen, Minlie Huang, et. al.| Tsinghua University, Microsoft Research Asia| <details><summary><small>This paper presents ITER-RETGEN ...</small></summary><small>This work propose **ITER-RETGEN**, which iterates retrieval-augmented generation and generation-augmented retrieval. Besides, they find that exact match can significantly underestimate the performance of LLMs, and using LLMs to evaluate is more reliable.</small></details>| <sub>HotpotQA, 2WikiMHQA, MuSiQue, Feverous, StrategyQA</sub> |
|2023/10/17| [SELF-RAG: Learning To Retrieve, Generate, and Critique  Through SELF-Reflection](https://arxiv.org/pdf/2310.11511) [[code](https://github.com/AkariAsai/self-rag): ![](https://img.shields.io/github/stars/AkariAsai/self-rag.svg?style=social)]|YAkari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, Hannaneh Hajishirzi|University of Washington|<details><summary><small>This paper presents *Self-RAG* ...</small></summary><small>This work introduces a framework called Self-Reflective Retrieval-Augmented Generation that enhances an LM’s quality and factuality through retrieval and self-reflection. It trains a single LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens.</small></details>| <sub>PubHealth, ARC-Challenge, PopQA, TRiviaQA, ALCE-ASQA</sub> |
|2023/10/8| [Self-Knowledge Guided Retrieval Augmentation for Large Language Models](https://arxiv.org/abs/2310.05002) [[code](https://github.com/THUNLP-MT/SKR): ![](https://img.shields.io/github/stars/THUNLP-MT/SKR.svg?style=social)]|Yile Wang, Peng Li, Maosong Sun, Yang Liu| Tsinghua University|<details><summary><small>This paper presents *SKR* ...</small></summary><small>This work nvestigate eliciting the model's ability to recognize what they know and do not know (which is also called self-knowledge) and propose Self-Knowledge guided Retrieval augmentation (SKR), a simple yet effective method which can let LLMs refer to the questions they have previously encountered and adaptively call for external resources when dealing with new questions.</small></details>| <sub>TemporalQA, CommonsenseQA, TabularQA, StrategyQA, TruthfulQA</sub> |
|2023/6/22 | [Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions](https://arxiv.org/abs/2212.10509) <br>[[code](https://github.com/stonybrooknlp/ircot): ![](https://img.shields.io/github/stars/stonybrooknlp/ircot.svg?style=social)] | Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal| Stony Brook University, Allen Institute for AI| <details><summary><small>This paper presents IRCoT ...</small></summary><small>This work propose **IRCoT**, which interleaves CoT generation and retrieval steps to guid the retrieval by CoT and vice-versa. Two steps: 1) reason step generates next CoT sentence based on question, retrieved passage, and CoT sentences; 2) retrieval step retrieves K more passages based on the last CoT sentence.</small></details>| <sub>HotpotQA,2WikiMHQA, MuSiQue, and IIRC</sub> |

## 4. Preference (Dual) Alignment Methods <a id="align"></a>
| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/07/18 | [Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation](https://arxiv.org/pdf/2406.18676) [[code](https://github.com/dongguanting/DPA-RAG): ![](https://img.shields.io/github/stars/dongguanting/DPA-RAG.svg?style=social)]| Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen|Renmin University of China|<details><summary><small>This paper presents *DPA-RAG* ...</small></summary><small>DPA-RAG consists of three key components: (1) Preference Knowledge Construction: it first extracts the specific knowledge that significantly affects LLMs’ reasoning preferences. Then we introduce five query augmentation strategies and a quality filtering process to synthesize high-quality preference knowledge. (2) Reranker-LLM Alignment: it designs multi-grained alignment tasks for fine-tuning a preference-aligned reranker. (3) LLM Self-Alignment: it introduces a pre-aligned phrase prior to the vanilla SFT stage.</small></details>| <sub>NQ, TriviaQA, HotpotQA, WebQSP</sub> |
|2024/03/15 | [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) [[code](https://github.com/ShishirPatil/gorilla): ![](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?style=social)]| Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng Shen, et al.|UC Berkeley|<details><summary><small>This paper presents *RAFT* ...</small></summary><small> RAFT leverages fine-tuning with question-answer pairs while referencing the documents in a simulated imperfect retrieval setting — thereby effectively preparing for the open-book exam setting. The RAFT is trained to answer the question (Q) from Document(s) (D) to generate answer (A), where A includes chain-of-thought reasoning.</small></details>| <sub>PubMed, HotpotQA, Gorilla</sub> |
|2023/10/08 | [Retrieval-Generation Synergy Augmented Large Language Models](https://arxiv.org/pdf/2310.05149.pdf) | Zhangyin Feng, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, Bing Qin| Harbin Institute of Technology| <details><summary><small>This paper presents ITRG ...</small></summary><small>This work propose **ITRG**, which contains two steps: 1) generation augmented retrieval (GAR) to expand the query based on previous iteration to help retrieve, 2) retrieval augmented generation (RAG) to generate new document to answer questions based on retrieved documents.</small></details>| <sub>NQ, TriviaQA, 2WikiMHQA, HotpotQA</sub> |
|2023/5/24| [REPLUG: Retrieval-Augmented Black-Box Language Models](https://arxiv.org/abs/2301.12652.pdf) [[code](https://github.com/swj0419/REPLUG): ![](https://img.shields.io/github/stars/swj0419/REPLUG.svg?style=social)]|Weijia Shi, Sewon Min, Michihiro Yasunaga, et. al.|University of Washington, Stanford University, KAIST, Meta AI|<details><summary><small>This paper presents REPLUT ...</small></summary><small>This work introduce REPLUG, which prepends each retrieved document and question separately to the LLM and ensembles output probabilities from different passes. Besides, it takes LM to score documents to supervise the dense retriever training.</small></details>| <sub>Pile, NQ, TriviaQA</sub> |
|2022/11/16| [Atlas: Few-shot Learning with Retrieval Augmented Language Models](https://arxiv.org/abs/2208.03299.pdf)<br> [[code](https://github.com/facebookresearch/atlas): ![](https://img.shields.io/github/stars/facebookresearch/atlas.svg?style=social)]|Gautier Izacard, Patrick Lewis, Maria Lomeli, et. al.|Meta AI, ENS, PSL University, Inria, UCL|<details><summary><small>This paper presents Atlas ...</small></summary><small>This work present Atlas, a retrieval (Contriever) augmented language model (T5) by carefully designed training, i.e., 1) jointly pre-train the retriever and LLM using unsupervised output, 2) efficient retriever fine-tuning (including full index update, reranking, and query-side fine-tuning).</small></details>| <sub>KILT, MMLU, NQ, TriviaQA</sub> |

