# Awesome resources about rank component in the RAG system

üî• **Must-read papers for generate component in RAG.**

üèÉ **Coming soon: Add one-sentence intro to each paper.**

üåü **We greatly appreciate any contributions via PRs, issues, emails, or other methods.**


## Introduction

Coming soon ...


## Table of Content (ToC)


- [Retrieval Stage](#retrieval)
  - [Sub-title 1](#subtitle1)
  - [Sub-title 2](#subtitle2)
- [Rerank Stage](#rerank)
  - [Sub-title 1](#1-sub-rerank)
  - [Sub-title 2](#2-sub-rerank)






## 1. Methods

### 1.1 Sub-title 1


- [2023/10] **This is the paper Title** *Authors et al. arXiv.* [[paper](https://arxiv.org/abs/2310.02071)] [[code](https://github.com/PKUnlp-icler/PCA-EVAL), ![](https://img.shields.io/github/stars/Tongji-KGLLM/RAG-Survey.svg?style=social)]
  - This work proposes XXXXX, which benchmarks document ranking via XXX methods and XXX methods from XXXX, XXX, and XXXX......

## 2. Datasets

### 1.1 Sub-title 1


- [2022/04/12] **ASQA: Factoid Questions Meet Long-Form Answers** *Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, Ming-Wei Chang. arXiv.* [[paper](https://arxiv.org/abs/2204.06092)] [[dataset](https://huggingface.co/datasets/din0s/asqa)]
  - ASQA is the first long-form question answering dataset that focuses on ambiguous factoid questions.
