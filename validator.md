# Awesome resources about answer enhancement component in the RAG system

üî• **Must-read papers for answer enhancement component in RAG.**

üèÉ **Coming soon: Add one-sentence intro to each paper.**

üåü **We greatly appreciate any contributions via PRs, issues, emails, or other methods.**


## Introduction

The answer generated by LLMs are tend to be haullucinations. To overcome this, it would be better to introduce an additional component to increase the quality of the answer, namely **answer enhancement** component. The


## Table of Content (ToC)

- [Answer Verification](#verify)
	- [Attribution Detection](#attribution)
- [Reasoning-based (CoT) Filtering](#cot)


## 1. Answer Verifiaction <a id="verify"></a>

### 1.1 Attribution Detection <a id="attribution"></a>
| Date       | Title                                                                                                           | Authors                                  | Orgnization                                                                                                   | Abs                                                                                             |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/10/07| [Automatic Evaluation of Attribution by Large Language Models](https://arxiv.org/pdf/2305.06311.pdf) <br> [[code](https://github.com/OSU-NLP-Group/AttrScore): ![](https://img.shields.io/github/stars/OSU-NLP-Group/AttrScore.svg?style=social) |Xiang Yue, Boshi Wang, Ziru Chen, et. al.|The Ohio State University | <small>This work tries to evaluate the attribution ability (3 types: attributable, extrapolatory, contradictory) of existing LLMs by introducing two benchmarks (i.e., AttrEval-Simulation and AttrEval-GenSearch). It also introduces two types of automatic evaluation methods: 1) Prompting LLMs, 2) Fine-tuning LMs on Repurposed Data. </small>|

## 2. Reasoning-based (CoT) Filtering <a id="cot"></a>

| Date       | Title                                                                                                           | Authors                                  | Orgnization                                                                                                   | Abs                                                                                             |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/12/31| [Rethinking with Retrieval: Faithful Large Language Model Inference](https://arxiv.org/abs/2301.00303.pdf) <br> [[code](https://github.com/HornHehhf/RR): ![](https://img.shields.io/github/stars/HornHehhf/RR.svg?style=social) |Hangfeng He, Hongming Zhang, Dan Roth|University of Rochester, Tencent AI Lab Seattle, University of Pennsylvania | <small>This work propose a novel post-processing approach, rethinking with retrieval (RR), which uses decomposed reasoning steps obtained from CoT prompting to retrieve relevant docs for LLMs. Four steps: 1)CoT prompting to generate explanation E and prediction P for query Q. 2)Sampling diverse reasoning path R (i.e., E + P), 3)knowledge K retrieval for each path, 4)faithful inference (NLI model) for each R+K.</small>|